{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a1e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3789468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████                                                                              | 5/100 [02:04<39:46, 25.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 상황: 40 개의 뉴스 수집 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▉                                                                             | 6/100 [02:33<41:29, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 상황: 50 개의 뉴스 수집 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|█████████████████████▊                                                           | 27/100 [11:19<28:42, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 상황: 220 개의 뉴스 수집 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 28/100 [11:47<29:56, 24.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 상황: 230 개의 뉴스 수집 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                         | 29/100 [12:14<30:26, 25.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행 상황: 240 개의 뉴스 수집 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███████████████████████████▌                                                     | 34/100 [14:28<29:24, 26.74s/it]"
     ]
    }
   ],
   "source": [
    "# 주제: 이스라엘 전쟁\n",
    "\n",
    "import requests # 웹 페이지 내용 가져오기\n",
    "import logging # 로그 메세지 기록 및 관리\n",
    "\n",
    "import pandas as pd # 데이터 구조화 및 분석을 위한 데이터 프레임 생성\n",
    "from tqdm import tqdm # 진행 상황을 시각적으로 표시\n",
    "\n",
    "from bs4 import BeautifulSoup # HTML 문서 파싱 및 원하는 정보 추출\n",
    "\n",
    "import pickle # 직렬화\n",
    "import time # 시간 관련 작업에 사용\n",
    "\n",
    "\n",
    "# _____________________________________________________________________\n",
    "\n",
    "\n",
    "# 로깅 설정  / logging.basicConfig()함수\n",
    "# 뉴스 크롤링한 시간 기록\n",
    "\n",
    "# (1. 경로, 2. 레벨(정보성 메세지), 3. 출력형식)\n",
    "logging.basicConfig(filename = 'crawler.log', \n",
    "                    level = logging.INFO, \n",
    "                    format = '%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "\n",
    "# 함수로 크롤링 작업 분리\n",
    "def get_news_urls(query, page):\n",
    "    \n",
    "    # 이스라엘 전쟁 1개월 url\n",
    "    url_template = (\"https://search.naver.com/search.naver\"\n",
    "                    \"?where=news&query={query}&sm=tab_opt&sort=0&photo=0&field=0&pd=2\"\n",
    "                    \"&ds=&de=&docid=&related=0&mynews=0&office_type=0\"\n",
    "                    \"&office_section_code=0&news_office_checked=&nso=so:r,p:1m\"\n",
    "                    \"&is_sug_officeid=0&office_category=0&service_area=0&start={page}\")\n",
    "    \n",
    "    # 각각을 매개변수로 받은 값으로 대체\n",
    "    url = url_template.format(query=query, page=page)\n",
    "    \n",
    "    \n",
    "    # HTTP 요청 헤더: 사용자 에이전트를 설정하여 웹브라우저 처럼 보이도록 함\n",
    "    # User-Agent: 웹 서버가 요청을 거부하지 못하도록 함 + 봇으로 인식됨을 방지\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
    "    \n",
    "    # 해당 url에 GET 요청을 보냄\n",
    "    # 오류를 처리하는 방법 정의: 예외 발생\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    \n",
    "    # 받은 응답 내용: BeautifulSoup으로 파싱 \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    urls = [a['href'] for a in soup.select(\"a.info\")]\n",
    "    \n",
    "    # 선택된 url 리스트로 반환\n",
    "    return urls\n",
    "\n",
    "#_______________________________________________________________\n",
    "\n",
    "\n",
    "# 뉴스 제목과 내용 관련 함수\n",
    "def get_news_content(url):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"}\n",
    "        \n",
    "        # 타임아웃: 대기 시간 제한\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        title = soup.select_one(\".media_end_head_headline\")\n",
    "        \n",
    "        \n",
    "        content = soup.select_one(\"#dic_area\")\n",
    "        \n",
    "        \n",
    "        if title and content:\n",
    "            return title.text.strip(), content.text.strip()\n",
    "    \n",
    "    \n",
    "    # try에서 발생한 예외 처리: 오류를 로그에 기록\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Failed to crawl {url}: {e}\")\n",
    "    \n",
    "    # 1. 예외 발생, 2. 제목&내용 없을 경우: 둘다 None으로 처리\n",
    "    return None, None\n",
    "\n",
    "\n",
    "#_________________________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "# 크롤링 설정\n",
    "query = \"이스라엘 전쟁\"\n",
    "total_pages = 100 # 스크롤 대신 사용: 임의의 수 100으로 진행\n",
    "\n",
    "\n",
    "\n",
    "# 크롤링 진행 상태 표시: tqdm 함수\n",
    "with tqdm(total=total_pages) as pbar:\n",
    "    news_data = []\n",
    "    page = 1\n",
    "    \n",
    "    while page <= total_pages * 10:\n",
    "        \n",
    "        news_urls = get_news_urls(query, page)\n",
    "        \n",
    "        if not news_urls:\n",
    "            break\n",
    "        \n",
    "        for news_url in news_urls:\n",
    "            title, content = get_news_content(news_url)\n",
    "            \n",
    "            # 제목과 내용이 둘다 존재할 경우에만\n",
    "            if title and content:\n",
    "                news_data.append({\"date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"), \"title\": title, \"content\": content, \"url\": news_url})\n",
    "        \n",
    "        \n",
    "        page += 10\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if len(news_data) % 10 == 0:\n",
    "            print(f\"진행 상황: {len(news_data)} 개의 뉴스 수집 완료\")\n",
    "        time.sleep(1)  # 서버 부하를 줄이기 위해 잠시 대기\n",
    "\n",
    "        \n",
    "\n",
    "# 데이터프레임으로 변환 후 pickle 파일로 저장\n",
    "df = pd.DataFrame(news_data)\n",
    "with open(\"news_data10.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)\n",
    "\n",
    "    \n",
    "# 저장한 pickle 파일 불러오기\n",
    "with open(\"news_data10.pkl\", \"rb\") as f:\n",
    "    loaded_df = pickle.load(f)\n",
    "\n",
    "    \n",
    "# CSV로 저장\n",
    "output_file = \"naver_news_war10.csv\"\n",
    "loaded_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "logging.info(f\"크롤링 완료: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# CSV 파일 로드\n",
    "input_file = r\"C:\\Users\\jkl12\\개인적 활동\\naver_news_war3.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 데이터프레임 출력 (기본 형태)\n",
    "# print(df.head())\n",
    "\n",
    "# 긴 문자열을 줄이는 함수 정의\n",
    "def shorten_text(text, length=20):\n",
    "    if len(text) > length:\n",
    "        return text[:length] + '...'\n",
    "    return text\n",
    "\n",
    "# 데이터프레임 정리\n",
    "# 예: 'date', 'title', 'content' 컬럼만 선택하고 'date' 컬럼을 기준으로 정렬\n",
    "df_cleaned = df[['date', 'title', 'content']].sort_values(by='date')\n",
    "\n",
    "# 문자열 길이를 줄임\n",
    "df_cleaned['title'] = df_cleaned['title'].apply(shorten_text)\n",
    "df_cleaned['content'] = df_cleaned['content'].apply(shorten_text)\n",
    "\n",
    "# 정리된 데이터프레임 출력\n",
    "print(df_cleaned.head())\n",
    "print(df_cleaned.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7cb5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 워드 클라우드: 이스라엘 전쟁\n",
    "\n",
    "import re # 정규표현식 사용: 텍스트 데이터를 클렌징\n",
    "import pandas as pd # 데이터 프레임 사용\n",
    "\n",
    "import os # 파일의 존재 검사\n",
    "from collections import Counter # 단어의 빈도수 계산\n",
    "\n",
    "import nltk # 자연어 처리: 텍스트 토큰화를 위해 사용\n",
    "from nltk.tokenize import word_tokenize # 텍스트 데이터를 단어 단위로 분할하기\n",
    "\n",
    "import pickle # pickle 파일 로드\n",
    "\n",
    "# 워드 클라우드\n",
    "from wordcloud import WordCloud # 생성\n",
    "import matplotlib.pyplot as plt # 시각화\n",
    "from matplotlib import font_manager, rc # 폰트\n",
    "\n",
    "\n",
    "# ________________________________________________________\n",
    "\n",
    "\n",
    "# 불용어 사전 파일 경로\n",
    "stopword_file_path1 = r\"C:\\Users\\jkl12\\Downloads\\불용어 사전.txt\"\n",
    "stopword_file_path2 = r\"C:\\Users\\jkl12\\Downloads\\불용어 사전2.txt\"\n",
    "\n",
    "\n",
    "# 불용어 사전 로드 함수\n",
    "def load_stopwords(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        \n",
    "        # 줄 단위로 나누기\n",
    "        stopwords = file.read().splitlines()\n",
    "    \n",
    "    # 불용어 리스트를 집합(set)으로 변환하여 중복 제거\n",
    "    return set(stopwords)\n",
    "\n",
    "# 불용어 사전 호출 및 변수에 저장\n",
    "custom_stopwords1 = load_stopwords(stopword_file_path1)\n",
    "custom_stopwords2 = load_stopwords(stopword_file_path2)\n",
    "\n",
    "\n",
    "# ___________________________________________________________\n",
    "\n",
    "두 개의 불용어 사전 파일을 로드하여 불용어 목록을 만드는 과정을 수행합니다. \n",
    "# news_data3.pkl 파일 로드\n",
    "with open(\"news_data3.pkl\", \"rb\") as f:\n",
    "    news_data = pickle.load(f)\n",
    "\n",
    "    \n",
    "# 뉴스 데이터에서 텍스트 추출\n",
    "text_data = ' '.join(news_data['content'])\n",
    "\n",
    "\n",
    "# 텍스트 클렌징\n",
    "def clean_text(text):\n",
    "    \n",
    "    # 특수 문자 및 숫자 제거\n",
    "    text = re.sub(r'[^a-z가-힣\\s]', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 클렌징된 텍스트 생성\n",
    "cleaned_text = clean_text(text_data)\n",
    "\n",
    "\n",
    "# _________________________________________________________\n",
    "\n",
    "\n",
    "\n",
    "# NLTK 데이터 다운로드 (최초 1회 실행)\n",
    "# 문장 분리 및 단어 토큰화를 위해 필요한 데이터\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 토큰화: 단어 단위로 분할\n",
    "tokens = word_tokenize(cleaned_text)\n",
    "\n",
    "\n",
    "# 불용어 사전에 포함된 단어를 제외한 단어들만 남기기\n",
    "# 빈도수 계산\n",
    "\n",
    "filtered_tokens1 = [word for word in tokens if word not in custom_stopwords1]\n",
    "word_counts1 = Counter(filtered_tokens1)\n",
    "\n",
    "filtered_tokens2 = [word for word in tokens if word not in custom_stopwords2]\n",
    "word_counts2 = Counter(filtered_tokens2)\n",
    "\n",
    "\n",
    "# 나눔고딕 폰트 설정\n",
    "font_path = r'C:\\Users\\jkl12\\OneDrive\\바탕 화면\\내 파일\\폰트\\nanum-all\\나눔 글꼴\\나눔스퀘어네오\\NanumSquareNeo-bRg.ttf'\n",
    "\n",
    "# 폰트 설정\n",
    "font_name = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "# 워드 클라우드 생성\n",
    "wordcloud1 = WordCloud(width=1000, height=500, background_color='white', font_path=font_path).generate_from_frequencies(word_counts1)\n",
    "wordcloud2 = WordCloud(width=1000, height=500, background_color='white', font_path=font_path).generate_from_frequencies(word_counts2)\n",
    "\n",
    "# 워드 클라우드 시각화\n",
    "plt.figure(figsize=(12, 18))\n",
    "\n",
    "# 첫 번째 워드 클라우드\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.title('Word Cloud 1\\n', fontproperties=font_manager.FontProperties(fname=font_path, size=20))\n",
    "plt.axis('off')\n",
    "plt.text(0, -0.4, \n",
    "         '1. 가자지구 (Gaza Strip): 팔레스타인의 한 지역으로, 이스라엘과 오랜 기간 갈등을 겪어온 곳\\n\\n'\n",
    "         '2. 라파 (Rafah): 가자지구 남부에 위치한 도시, 이집트와의 경계에 있음\\n\\n'\n",
    "         '3. 네타냐후 (Netanyahu): 베냐민 네타냐후는 이스라엘의 전 총리\\n\\n' \n",
    "         '4. 미국 (United States): 이스라엘의 주요 동맹국\\n\\n'\n",
    "         '5. 팔레스타인 (Palestine): 가자지구, 서안지구(웨스트뱅크)가 팔레스타인 자치 정부의 통제하에 있음, 이스라엘과 갈등이 지속되고 있음\\n\\n',\n",
    "         ha='left', va='center', \n",
    "         transform=plt.gca().transAxes, fontsize=10, fontproperties=font_manager.FontProperties(fname=font_path))\n",
    "\n",
    "\n",
    "# 두 번째 워드 클라우드\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(wordcloud2, interpolation='bilinear')\n",
    "plt.title('Word Cloud 2 \\n 가자지구, 라파, 베냐민, 네타냐후, 미국, 팔레스타인 제외\\n', fontproperties=font_manager.FontProperties(fname=font_path, size=20))\n",
    "plt.axis('off')\n",
    "plt.text(0, -0.4, \n",
    "         '1. 하마스 (Hamas): 가자지구를 통치하는 팔레스타인 무장 정파, 이스라엘과의 무력 충돌의 주요 행위자 중 하나.\\n\\n'\n",
    "         '2. 이란 (Iran): 팔레스타인(하마스) 지원 및 지지 의사 표명 \\n\\n'\n",
    "         '3. 최남단 (Southernmost): 가자지구의 남쪽 경계는 이집트와 접함, 무기 밀수와 인도적 지원 경로.\\n\\n'\n",
    "         '4. 이집트 (Egypt): 이스라엘과 팔레스타인 사이의 중재자 역할.\\n\\n'\n",
    "         '5. 앤토니 블링컨(Antony Blinken) 미국의 외교관 & 정치인, 2021년 1월부터 조 바이든 대통령의 행정부에서 국무장관 역임 중 \\n\\n'\n",
    "         '6. 갈란트 (Gallant): 요아브 갈란트는 이스라엘의 군사 및 정치 지도자 중 한 명.',\n",
    "         ha='left', va='center', \n",
    "         transform=plt.gca().transAxes, fontsize=10, fontproperties=font_manager.FontProperties(fname=font_path))\n",
    "\n",
    "\n",
    "\n",
    "# 두 워드 클라우드 간격 조정\n",
    "plt.subplots_adjust(hspace=1.5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
